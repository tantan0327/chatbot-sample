{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f633e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8bb4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rinna/japanese-gpt2-medium'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "input_message = \"死にたいです。\"\n",
    "\n",
    "input_ids = tokenizer.encode(\n",
    "    \"私: \" + input_message + \"\\nAI: \",\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "084d258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#文章生成\n",
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids, #エンコードした入力文\n",
    "    max_length=60,\n",
    "    temperature=0.3, #1に近づくほどよりクリエイティブな文章に、0に近づくと論理的で問題に対して正確に返答する\n",
    "    repetition_penalty=1.0, #同じ文章の繰り返しを減らす\n",
    "    do_sample=True, #num_return_sequencesを複数回指定する場合はTrue\n",
    "    num_return_sequences=10 #一度の実行で生成する文章の数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7039e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 文章生成 1 ===\n",
      " 私は、あなたが私を死なせてしまったので、私はあなたを死なせてしまったのです。 \n",
      "=== 文章生成 2 ===\n",
      " そうですね、そうですね。 <unk> : でも、もう、そんなこと言ってられないですね。 <unk> : そうですね、そうですね。 <unk> : そうですね。 <unk> : \n",
      "=== 文章生成 3 ===\n",
      " 私も死にたいです。 <unk> : 私も死にたいです。 <unk> : 私も死にたいです。 <unk> : 私も死にたいです。 <unk> : 私も死にたいです。 <un\n",
      "=== 文章生成 4 ===\n",
      " 私、あなたのことが大好きです。 <unk> : あなたは私に恋してるの? <unk> : あなたは私のことを好きです。 <unk> : あなたは私に恋してるの? <un\n",
      "=== 文章生成 5 ===\n",
      " 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いで\n",
      "=== 文章生成 6 ===\n",
      " さて、あなたは、どうやって、この世界から、この世界へと、 <unk> : 私は、この世界から、この世界へと、この世界へと、この世界へと、 <unk> : あなたは、この\n",
      "=== 文章生成 7 ===\n",
      " 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いです。 <unk> : 私、死ぬのが怖いで\n",
      "=== 文章生成 8 ===\n",
      " ああ、そうだ。 <unk> : 私も死にたい。 <unk> : ああ、そうだ。 <unk> : ああ、そうだ。 <unk> : ああ、そうだ。 <unk>\n",
      "=== 文章生成 9 ===\n",
      " どうして私だけこんな目に遭わなきゃいけないんですか? \n",
      "=== 文章生成 10 ===\n",
      " ああ、そうだ。 私は、自分の人生を、自分の手で切り開いていきたい。 <unk> : 私には、まだ、やりたいことがある。 <unk> : 私は、自分の人生を、自分の手で切り\n"
     ]
    }
   ],
   "source": [
    "#生成した文章をトークンからテキストにデコード\n",
    "for i, output_sequence in enumerate(output_sequences):\n",
    "    print(f\"=== 文章生成 {i + 1} ===\")\n",
    "    output_sequence = output_sequence.tolist()\n",
    "\n",
    "    # トークンからテキストにデコード\n",
    "    text = tokenizer.decode(\n",
    "        output_sequence, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    total_text = (\n",
    "        text[len(tokenizer.decode(input_ids[0], clean_up_tokenization_spaces=True)):]\n",
    "    )\n",
    "\n",
    "    slice_potsition = total_text.find('AI:')\n",
    "    edited_text = total_text[:slice_potsition]\n",
    "    slice_potsition = edited_text.find('私:')\n",
    "    edited_text = edited_text[:slice_potsition]\n",
    "    print(edited_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc982cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
